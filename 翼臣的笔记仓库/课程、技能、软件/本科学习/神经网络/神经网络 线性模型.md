---
title: 实验使用numpy创建数组
author: 杨翼臣
date created: 星期三, 3月1日 2023, 6:07:47 晚上
date modified: 星期二, 6月6日 2023, 2:39:55 下午
tags: [神经网络]
aliases: 
---
# 实验使用numpy创建数组
## answer
[answer](https://blog.csdn.net/weixin_54375830/article/details/122599213 )


# 人工神经元
![[uDZxTajclIbLojKO-1809cc9e-3927-e851-9667-13980163b40c.png|600]]

# 感知机模型
![[uDZxTajclIbLojKO-ced7356a-4fff-c147-9f0d-d0210f546b94.png|600]]




# 感知机模型的化简变化
![[uDZxTajclIbLojKO-302b00a5-39e2-1579-12b2-1e6c299d1878.png|600]]



![[uDZxTajclIbLojKO-7d9119c5-7770-bcf1-2d64-59486764f9b8.png|600]]

# 激活函数
## 什么是激活函数？
在神经网络中，每个神经元接收到一些**输入信号**，它们需要进行某种计算**以生成输出信号。** 激活函数就负责这一部分。
在神经网络中，激活函数（Activation Function）是一种用于**对神经元的输入进行非线性变换的函数**。它通常被**用于将神经元的输出限制在一定范围内，如将输出限制在0和1之间或者在-1和1之间。** 激活函数在神经网络中的作用非常重要，因为它们能够增加网络的非线性能力，使神经网络可以学习更加复杂的模式和特征。常见的激活函数包括Sigmoid、ReLU、Tanh、Softmax等。
## 激活函数的性质
![[uDZxTajclIbLojKO-a8bb5c51-8653-6dc6-f01e-15c5d3623337.png|600]]
- 连续可导的非线性函数
- 简单
- 激活函数的导函数的值域要在一个合适的区间


## 常见的激活函数
### sigmoid函数
![[Pasted image 20230308192050.png|600]]
`sigmoid(x) = 1 / (1 + exp(-x))`
![[uDZxTajclIbLojKO-655e93d7-ac85-8fa9-83aa-469750e5aefb.png|600]]
<center>（sigmoid函数）</center>

![[uDZxTajclIbLojKO-324f30f6-0e9a-91f6-16ef-e95a0f9fe05c.png|600]]
看做挤压函数，把所有实数范围内的输入都挤压到（0,1）
- 输入值在0左右时，就近似线性函数
- 输入值越偏0远，就对输入进行抑制。
- 偏0偏的越远会被挤到接近1，偏0偏的近的会被挤到0.


### logistic函数
logistics 函数是特殊的sigmoid函数形式。
logistic(x) = 1 / (1 + e^(-kx))，
sigmoid函数是k=1时的函数。
当k取1时，logistic函数就退化成了标准的sigmoid函数。

>因此，可以认为sigmoid函数是一种更通用的函数，而logistic函数是在sigmoid函数基础上做了特定的限制。在实际应用中，根据具体的问题和需求，可以选择使用sigmoid函数或logistic函数


### Tanh函数
![[Pasted image 20230308192028.png|600]]
`tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`
![[uDZxTajclIbLojKO-30a35cd2-0c55-a290-ea9b-c5776568ce78.png|600]]

### 导数图像
![[uDZxTajclIbLojKO-706868d5-1f1c-1cf1-9b47-b04042c4d8cb.png|600]]



### sigmoid函数和tanh函数两者的区别
- 它们的主要区别在于函数值的范围和函数的形状。
- Sigmoid函数将输入的值映射到一个在0到1之间的范围内，公式为：
`sigmoid(x) = 1 / (1 + exp(-x))`
因此，它常被用作二元分类问题的输出层激活函数，输出值可以被解释为概率。但是，当输入值较大或较小时，函数的梯度会接近于0，导致梯度消失问题，限制了神经网络的深度。
- Tanh函数将输入的值映射到一个在-1到1之间的范围内，公式为：
`tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`
因此，它可以用于解决二元分类和多元分类问题。它的输出在输入为负时为负，输入为正时为正，这使得它比sigmoid函数对数据分布的对称性更敏感，因此在某些情况下，它比sigmoid函数更好地推广到新数据上。此外，Tanh函数的梯度变化比sigmoid函数的梯度变化更大，因此Tanh函数可以减缓梯度消失的问题。
- 总的来说，Tanh函数比sigmoid函数更常用，但在某些情况下，sigmoid函数也有其独特的优势。


## 激活函数的实现
### 阶跃函数
![[uDZxTajclIbLojKO-477a6028-fddf-ffbb-6a71-b249f17dcf84.png|600]]
- 参数x只能接受实数且为浮点数。
- 不允许传入Numpy数组参数。
```python
def step_function(x):
	if x > 0:
		return 1
	else:
		return 0

```



# 学习算法的实现

